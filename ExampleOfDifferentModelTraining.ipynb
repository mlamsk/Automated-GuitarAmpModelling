{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55d45c3f",
   "metadata": {},
   "source": [
    "# Example of Different Model Training \n",
    "The following script illustrates the multiple methods of prepairing the data and training models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61903961",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python prep_wav.py -h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7523085e",
   "metadata": {},
   "source": [
    "# Normalized Snapshot Training without Distinct Test Set\n",
    "This is the simplest method available. All that is required is a recording of the clean input data and the processed/dirty output data at one condition (setting of knobs on the analog hardware).\n",
    "\n",
    "The ```-s``` option denotes a \"snapshot\" model. The first argument is the clean input wav file, the second argument is the processed output wave file. Optionally, the third and fourth arguments may be a clean test input wav file and a processed test output wav file. An example is shown below.\n",
    "\n",
    "The training will seed all random number generators with 39 and will run for 100 epochs.\n",
    "\n",
    "### CAUTION: The test data set is the same as the validaiton set. This will give a biased result on the performance of the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f8080d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python prep_wav.py \"LPB1_ex1\"\\\n",
    "-s \"./Recordings/20211003_LPB-1_5_min_Pink_Ramp_Clean.wav\" \\\n",
    "\"./Recordings/20211003_LPB-1_5_min_Pink_Ramp_Dirty.wav\" \\\n",
    " --normalize true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0560b568",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python dist_model_recnet.py -l RNN3-LPB1-ex1 -eps 5 --seed 39"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5001cdf9",
   "metadata": {},
   "source": [
    "# Snapshot with Random Training/Validation Split and Separate Test Set\n",
    "The following settings perform a random 20% split on between the training and validation data. The split works by slicing the input audio into 100 even slices and chosing a certain number of them. Also here is defined a separate test data set which prevents the biasing of the results from the validation information leaking. \n",
    "\n",
    "### CAUTION: The random split between training and validation data may give unexpected results because the size of the devisions is long enough to maintain time dependency which also means that the Central Limit Theorm is not valid. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c85348f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-Parameterized Data\n",
      "/home/micahtseng/Personal/mlamsk/python3Env/pytorchSandbox/Automated-GuitarAmpModelling/prep_wav.py:90: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  in_rate, in_data = wavfile.read(args.snapshot[0])\n",
      "/home/micahtseng/Personal/mlamsk/python3Env/pytorchSandbox/Automated-GuitarAmpModelling/prep_wav.py:91: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  out_rate, out_data = wavfile.read(args.snapshot[1])\n",
      "/home/micahtseng/Personal/mlamsk/python3Env/pytorchSandbox/Automated-GuitarAmpModelling/prep_wav.py:110: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  test_in_rate, test_in_data = wavfile.read(args.snapshot[2])\n",
      "/home/micahtseng/Personal/mlamsk/python3Env/pytorchSandbox/Automated-GuitarAmpModelling/prep_wav.py:111: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  test_out_rate, test_out_data = wavfile.read(args.snapshot[3])\n"
     ]
    }
   ],
   "source": [
    "!python prep_wav.py \"LPB1_ex2\"\\\n",
    "-s \"./Recordings/20211003_LPB-1_5_min_Pink_Ramp_Clean.wav\" \\\n",
    "\"./Recordings/20211003_LPB-1_5_min_Pink_Ramp_Dirty.wav\" \\\n",
    "\"./Recordings/20211003_LPB-1_Natalie_Guitar_Clean.wav\" \\\n",
    "\"./Recordings/20211003_LPB-1_Natalie_Guitar_Dirty.wav\" \\\n",
    "-rs 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fae3ae9c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "existing model file found, loading network\n",
      "cuda device available\n",
      "unimplemented audio data type conversion...\n",
      "unimplemented audio data type conversion...\n",
      "unimplemented audio data type conversion...\n",
      "unimplemented audio data type conversion...\n",
      "Epoch:  1\n",
      "current learning rate: 0.005\n",
      "Epoch:  2\n",
      "Val loss: tensor(0.2819)\n",
      "current learning rate: 0.005\n",
      "Epoch:  3\n",
      "current learning rate: 0.005\n",
      "Epoch:  4\n",
      "Val loss: tensor(0.2435)\n",
      "current learning rate: 0.005\n",
      "Epoch:  5\n",
      "current learning rate: 0.005\n",
      "Epoch:  6\n",
      "Val loss: tensor(0.2424)\n",
      "current learning rate: 0.005\n",
      "Epoch:  7\n",
      "current learning rate: 0.005\n",
      "Epoch:  8\n",
      "Val loss: tensor(0.2181)\n",
      "current learning rate: 0.005\n",
      "Epoch:  9\n",
      "current learning rate: 0.005\n",
      "Epoch:  10\n",
      "Val loss: tensor(0.2002)\n",
      "current learning rate: 0.005\n",
      "unimplemented audio data type conversion...\n",
      "unimplemented audio data type conversion...\n",
      "Done Training\n",
      "Testing the final Model\n",
      "Testing the best Model\n",
      "Finished Training: SimpleRNNLPB1_ex2_LSTM_hs20_pre_high_pass\n"
     ]
    }
   ],
   "source": [
    "!python dist_model_recnet.py -l RNN3-LPB1-ex2 -eps 10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd683b7",
   "metadata": {},
   "source": [
    "# Parameterized Model\n",
    "The following settings prepair the data to create a parameterized model. A parameterization configuration file must be created. An example configuration file is included. The example is for one parameter, but any number of parameters up to 65355-(number of audio chanels) parameters may be defined. The limit is due to the number of channels allowed in a WAV file. \n",
    "\n",
    "The training instructions must then be modified to included the extra inputs to the model as ```-is <parameters + audio channels>``` That is, the number of inputs to the model must be the number of parameters plus the number of audio chanels. So for our example, ```-is 2```.\n",
    "\n",
    "As is the default, the trainging and validation data is split on modulus of 5 which gives a 20 percent split.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3e47f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python prep_wav.py \"LPB1_Parameterized\" -p \"./Configs/Parameterization-Config.json\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d300edcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python dist_model_recnet.py -l RNN3-LPB1_Parameterized -eps 175 --seed 39 -lm False -is 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b95be7",
   "metadata": {},
   "source": [
    "# Two Parameter Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25dbd7a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!python prep_wav.py \"DS1_Parameterized\" -p \"./Configs/Parameterization-Config-2.json\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81179c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python dist_model_recnet.py -l RNN3-DS1_Parameterized -eps 200 --seed 39 -lm False -is 3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
